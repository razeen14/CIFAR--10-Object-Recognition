# -*- coding: utf-8 -*-
"""CIFAR - 10 Object Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11scphg89kmhOdpc6g64CxY2n31N50c7H
"""

!pip install kaggle

!ls

!pip install py7zr

import py7zr

archive = py7zr.SevenZipFile('/content/train.7z', mode='r')
archive.extractall()
archive.close()

# import py7zr

# archive = py7zr.SevenZipFile('/content/test.7z', mode='r')
# archive.extractall()
# archive.close()

"""Importing the Dependencies"""

import os
import numpy as np
import pandas as pd
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split

filename = os.listdir('/content/train')

type(filename)

len(filename)

print(filename[0:5])

"""Labels Processing"""

labels_df = pd.read_csv('/content/trainLabels.csv')

labels_df.shape

labels_df.head()

labels_df.tail()

labels_df['label'].value_counts()

labels_df['label']

labels_dictionary = {'airplane':0 , 'automobile':1 , 'bird':2 , 'cat':3 , 'deer':4 , 'dog':5 , 'frog':6 , 'horse':7 , 'ship':8 , 'truck':9}

labels = [labels_dictionary[i] for i in labels_df['label']]

print(labels[0:5])
print(labels[-5:])

"""Just Random Check"""

#displaying sample image

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/train/12197.png')

cv2_imshow(img)

labels_df[labels_df['id'] == 12197]

img = cv2.imread('/content/train/25703.png')

cv2_imshow(img)

labels_df[labels_df['id'] == 25703]

id_list = list(labels_df['id'])

print(id_list[0:5])
print(id_list[-5:])

"""Image Processing"""

# converting images to numpy arrays

train_data_folder = '/content/train/'

data = []

for id in id_list:
  image = Image.open(train_data_folder + str(id) + '.png')
  image = np.array(image)
  data.append(image)

type(data)

len(data)

type(data[0])

data[0].shape

data[0]

# convert images and label lists to numpy arrays

X = np.array(data)
Y = np.array(labels)

type(X)

print(X.shape)
print(Y.shape)

"""Train Test Split"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)
print(Y.shape, Y_train.shape, Y_test.shape)

# scaling the data

X_train_scaled = X_train / 255
X_test_scaled = X_test / 255

X_train_scaled

"""Building the Neural Network"""

import tensorflow as tf
from tensorflow import keras

num_of_classes = 10

# setting up the layers of Neural Network

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(32,32,3)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(num_of_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc']
)

# training the neural network

model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10)

"""ResNet50"""

from tensorflow.keras import Sequential, models, layers
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import load_model
from tensorflow.keras.models import Model
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras import optimizers

convolutional_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3))
convolutional_base.summary()

num_of_classes = 10

model = models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(convolutional_base)
model.add(layers.Flatten())
model.add(layers.BatchNormalization())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.BatchNormalization())
model.add(layers.Dense(num_of_classes, activation='softmax'))

model.compile(
    optimizer=optimizers.RMSprop(learning_rate=2e-5),
    loss='sparse_categorical_crossentropy',
    metrics=['acc']
)

history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10)

loss, accuracy = model.evaluate(X_test_scaled, Y_test)
print("Test Accuracy: ", accuracy)

h = history

#plot the loss function value

plt.plot(h.history['loss'], label='train loss')
plt.plot(h.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

#plot the accuracy

plt.plot(h.history['acc'], label='train accuracy')
plt.plot(h.history['val_acc'], label='validation accuracy')
plt.legend()
plt.show()